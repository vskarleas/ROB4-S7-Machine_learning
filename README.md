# Machine Learning - Cours Magistraux (CM), et Travaux Pratiques (TP)

## Français

Bienvenue dans le dépôt du module **Apprentissage Automatique** (Polytech Sorbonne). Ce module couvre des concepts fondamentaux et avancés de l'apprentissage automatique, des algorithmes supervisés et non supervisés, ainsi que des architectures de réseaux de neurones modernes.

### Sujets abordés :
- **K-plus-proches-voisins (KPPV)** : Approche simple et efficace pour les problèmes de classification.
- **Pouvoir discriminant** :
  - Codage différent pour des exemples appartenant à des classes distinctes (forte variance inter-classes).
- **Pouvoir unifiant** :
  - Codage similaire pour les exemples d'une même classe (faible variance intra-classe).
- **Stabilité/Invariance** :
  - Résistance au bruit.
  - Invariance en fonction des applications (translation, rotation, échelle, etc.).
- **Faible dimensionnalité** : Réduction et simplification des données.
- **Codage rétinien** : Inspiration biologique pour le traitement de données.
- **Choix de la base de données** : Importance de la qualité et de la pertinence des datasets.
- **Compromis Biais-Variance** : Comprendre et équilibrer ce compromis essentiel.
- **Méthodes supervisées et non supervisées** : Exploration et applications.
- **Méthodes génératives et discriminatives** : Différences fondamentales et utilisation.
- **Réseaux de Neurones** :
  - Perceptron simple et multi-couches.
  - Activation avec **LeakyRELU**.
  - Importance du taux d'apprentissage (**learning rate**).
  - Réseaux convolutifs (**CNN**).

---

## English

Welcome to the repository for the **Machine Learning** module. This course delves into core and advanced concepts of machine learning, covering supervised and unsupervised algorithms, as well as modern neural network architectures.

### Topics Covered:
- **K-Nearest Neighbors (KNN)**: A simple yet effective approach for classification problems.
- **Discriminant Power**:
  - Coding that varies significantly for examples from different classes (high inter-class variance).
- **Unifying Power**:
  - Coding that remains consistent within examples of the same class (low intra-class variance).
- **Stability/Invariance**:
  - Robustness to noise.
  - Invariance to translation, rotation, and scale, depending on application requirements.
- **Low Dimensionality**: Focus on data reduction and simplification.
- **Retinal Coding**: Biologically inspired data processing.
- **Database Selection**: Importance of dataset quality and relevance.
- **Bias-Variance Tradeoff**: Understanding and balancing this critical tradeoff.
- **Supervised and Unsupervised Methods**: Exploration and applications.
- **Generative vs Discriminative Methods**: Key distinctions and applications.
- **Neural Networks**:
  - Single-layer and multi-layer perceptrons.
  - Activation with **LeakyRELU**.
  - Role of **learning rate**.
  - **Convolutional Neural Networks (CNNs)**.

---

### License Information

**Machine Learning - Polytech Sorbonne** © 2024 by Vasileios Filippos Skarleas is licensed under the [Creative Commons Attribution-NonCommercial 4.0 International](https://creativecommons.org/licenses/by-nc/4.0/). 

This repository may include content subject to copyright from other owners.

---
